---
title: "ğŸ“„Language Models are Few-Shot Learners (GPT-3) ë…¼ë¬¸ ë¦¬ë·°"
date: 2020-06-23
tags: GPT-3 OpenAI
---


# ë“¤ì–´ê°€ê¸°ì— ì•ì„œ

- ë…¼ë¬¸: Language Models are Few-Shot Learners

- URL: [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)

í•´ë‹¹ í¬ìŠ¤íŠ¸ëŠ” ë…¼ë¬¸ê³¼ ë‹¤ìŒì˜ 2ê°œì˜ ìœ íŠœë¸Œ ì˜ìƒì„ ë³´ë©° ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì˜ ë‚´ìš©ì„ ê¸°ë³¸ìœ¼ë¡œ í–ˆì§€ë§Œ, í•„ìš”ì— ë”°ë¼ ê³µë¶€í•œ ê²ƒë“¤ì„ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.

ê·¸ ì¤‘ì—ì„œë„ Yannic Kilcherì˜ ì±„ë„ì€ ìµœê·¼ ì—„ì²­ë‚œ ì†ë„ë¡œ ìµœì‹  ë…¼ë¬¸ë“¤ì„ ë¦¬ë·°í•´ì£¼ëŠ” ìœ íŠœë¸Œ ì±„ë„ì´ë‹¤.(ì •ë§ ë©‹ìˆëŠ” ì—°êµ¬ì ë° ìœ íŠœë²„) ë‹¤ë¥¸ ë¬´ì—‡ë³´ë‹¤ ìµœëŒ€ ê°•ì ì€ ë…¼ë¬¸ì´ ë‚˜ì˜¨ì§€ 1~2ì¼ë§Œì— ë¦¬ë·°ë¥¼ í•´ì£¼ë©°, ì‹¤ì œë¡œ ë…¼ë¬¸ì„ high levelì—ì„œ í•µì‹¬ ì•„ì´ë””ì–´ë§Œ ì§šì–´ì¤€ë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ëŸ¬í•œ NLP ì´ì™¸ì—ë„ ì •ë§ í¥ë¯¸ë¡œìš´ ë”¥ëŸ¬ë‹ ë…¼ë¬¸ ë¦¬ë·°ë“¤ì´ ë§ìœ¼ë‹ˆ ê¼­ í•œë²ˆ ë°©ë¬¸í•´ì„œ ì‚´í´ë³´ì„¸ìš”! ğŸ˜

- Minsuk Heo í—ˆë¯¼ì„: [[ë…¼ë¬¸ ë¦¬ë·°] GPT-3](https://www.youtube.com/watch?v=p24JUVgDkQk&t=669s)
- Yannic Kilcher: [GPT-3: Language Models are Few-Shot Learners (Paper Explained)](https://www.youtube.com/watch?v=SY5PvZrJhLE&t=29s)

## ë…¼ë¬¸ í•œ ì¤„ ìš”ì•½

![total-compute-used-during-training](/assets/total-compute-used-during-training.PNG)

ì–´ë§ˆë¬´ì‹œí•œ íŒŒë¼ë¯¸í„°(1,750ì–µê°œ)ë¥¼ ê°€ì§€ê³  fine-tuning ì—†ì´ few-shot learningì„ í†µí•´ ëª‡ëª‡ NLP taskì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.


# 0. Abstract

ë§ì€ ì–¸ì–´ ëª¨ë¸ë“¤ì€ í˜„ì¬ `pre-training â†’ fine-tuning` í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµë˜ê³  ìˆëŠ”ë°, ì´ëŠ” ì¶”ê°€ì ì¸ ë§ì€ ë ˆì´ë¸”ë˜ì–´ ìˆëŠ” ë°ì´í„°ì…‹ì´ í•„ìš”í•˜ë‹¤. ë§ì€ ë¦¬ì†ŒìŠ¤ë¥¼ í•„ìš”ë¡œ í•œë‹¤ëŠ” ë¬¸ì œì ê³¼ ë”ë¶ˆì–´ ì• ì´ˆì— ì‚¬ëŒì€ ëª‡ ì•ˆë˜ëŠ” ì˜ˆì œë¥¼ í†µí•´ì„œë„ ìƒˆë¡œìš´ NLP taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

* ì´ëŸ¬í•œ ê´€ì ì—ì„œ GPT-3ëŠ” íŒŒë¦¬ë¯¸í„°ì˜ ìˆ˜ë¥¼ 1,750ì–µê°œê¹Œì§€ ëŠ˜ë¦¬ê³ , fine-tuningê³¼ gradient updates ì—†ì´ few-shot demonstrationsë§Œì„ í†µí•´ NLP taskì—ì„œ ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤. (ì „ë¶€ ë‹¤ SOTAë¥¼ ë‹¬ì„±í•œ ê²ƒì€ ì•„ë‹ˆë‹¤.)
  - translation, question-answering, cloze(missing ë‹¨ì–´ë¥¼ ì±„ì›Œ ë„£ëŠ” í…ŒìŠ¤í¬) task, unscrambling words, 3-digit arithmetic(ì„¸ìë¦¬ ì‚°ìˆ˜) ë“±ì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì˜€ë‹¤.
* ë˜í•œ GPT-3ëŠ” ì‚¬ëŒì´ êµ¬ë³„ ë¶ˆê°€ëŠ¥í•œ ì •ë„ì˜ ì‹ ë¬¸ ê¸°ì‚¬ë¥¼ ì‘ì„±í•˜ê¸°ë„ í•˜ì˜€ë‹¤.
* ê·¸ ì™¸ í•´ë‹¹ ëª¨ë¸ê³¼ ê´€ë ¨í•œ ì‚¬íšŒì  ì´ìŠˆì— ëŒ€í•´ì„œë„ ë‹¤ë£¬ë‹¤.

# 1. Introduction

![bert-and-gpt](/assets/bert-and-gpt.PNG)

**GPT** (Generative Pretrained Transformer)ëŠ” Transformerì˜ Decoder ë¶€ë¶„ì„, **BERT** (Bidirectional Encoder Representations from Transformer)ëŠ” Transformerì˜ Encoderë¥¼ ì‚¬ìš©í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ê·¸ ê´€ê³„ê°€ ìŒë‘¥ì´ ìë§¤ì™€ ê°™ë‹¤. ì‹¤ì œë¡œ ê·¸ ë°œì „ì˜ ì—­ì‚¬ë¥¼ ë³´ë©´ `ELMO (2018.02) â†’ GPT-1 (2018.05) â†’ BERT (2018.10) â†’ XLNet (2019.07) â†’ GPT-2 (2019.02) â†’ RoBERTa (2019.07) â†’ ALBERT (2019.09) â†’ T5 (2019.10) â†’ ...` ì²˜ëŸ¼ ê°™ì€ Transformerì—ì„œ ì¶œë°œí•´ì„œ ì„œë¡œì˜ ì„±ëŠ¥ì„  ì—ì¹˜ë½ ë’¤ì¹˜ë½í•˜ë©´ì„œ ë°œì „í•´ì™”ë‹¤. ê¸°ë‚˜ê¸´ ì„ ì˜ì˜ ê²½ìŸ ëì— ë§ˆì¹¨ë‚´ ì´ë²ˆì—ëŠ” GPTë¥¼ ì¤„ê³§ ì—°êµ¬í•´ì˜¨ OpenAIì—ì„œ 2020ë…„ 05ì›” **GPT-3** ëª¨ë¸ì„ ë“¤ê³ ë‚˜ì™”ë‹¤.

`GPT â†’ GPT-2`
* Layer normalizationì´ ê°ê°ì˜ inputì˜ sub-blockìœ¼ë¡œ ì˜®ê²¨ì¡Œìœ¼ë©°, ë§ˆì§€ë§‰ self-attention blockì—ë„ ë”í•´ì§.
* A modified initialization which accounts for the accumulation on the residual path with model depth is used.
* residual layerì—ì„œ initialization ê°€ì¤‘ì¹˜ë¥¼ scaling.
* vocabulary 50,257ê°œê¹Œì§€ ì¦ê°€.
* context sizeë¥¼ 512ì—ì„œ 1024ë¡œ ì¦ê°€. ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ 512ê°œë¡œ ì¦ê°€.

`GPT-2 â†’ GPT-3`
* Transformer ë¶€ë¶„ì—ì„œ dense and locally banded sparse attention patternë¥¼ ì‚¬ìš©.

ì•ì„  ì—¬ëŸ¬ ì–¸ì–´ ëª¨ë¸ë“¤ì€ ì¼ë°˜ì ì¸ ì–¸ì–´ì— pre-trained í•˜ê³ , íŠ¹ì • taskì— ë§ê²Œ fine-tuningí•˜ê²Œ ë˜ëŠ”ë° ì• ì´ˆì— ì´ fine-tuningí•˜ëŠ” ê³¼ì •ì´ ë§Œë§Œì¹˜ ì•Šë‹¤.

1. fine-tuningì„ ìœ„í•´ì„  pre-trainedì„ ì˜ í–ˆë‹¤ê³ í•´ë„, í•´ë‹¹ taskë¥¼ ìœ„í•œ ë ˆì´ë¸”ë˜ì–´ ìˆëŠ” ì–‘ì§ˆì˜ ë°ì´í„°ì…‹ì´ ë˜ ë‹¤ì‹œ í•„ìš”.
2. fine-tuningì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ í•™ìŠµì‹œí‚¤ëŠ” ë° ë˜ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ê³¼ì •ì´ í•„ì—°ì .
3. íŠ¹ì • taskì— fine-tuning í•˜ëŠ” ê²ƒì€ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ëŒì´ ì–¸ì–´ë¥¼ ì´í•´í•˜ëŠ” ë°©ë²•ì€ ì•„ë‹˜.
4. ê±°ëŒ€í•œ ë°ì´í„°ì…‹ì— pre-trained í•œ í›„, fine-tuning í•˜ëŠ” ê²ƒì€ narrow task(íŠ¹ì • taskì— ëŒ€í•´ì„œë§Œ í•™ìŠµ)ì—ë§Œ í•™ìŠµí•˜ëŠ” ê²ƒ.

> ì¦‰, pre-trained + fine-tuning íŒ¨ëŸ¬ë‹¤ì„ì€ ì—¬ëŸ¬ ë¬¸ì œê°€ ìˆë‹¤.

![in-context-learning](https://user-images.githubusercontent.com/42036664/85543537-1f30f900-b655-11ea-9448-f6c60650dbc1.PNG)


* ì–¸ì–´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë™ì•ˆ `in-context learning`ìœ¼ë¡œ ë‹¤ì–‘í•œ íŒ¨í„´ ì¸ì§€ ëŠ¥ë ¥ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©

* ì‚¬ì¹™ì—°ì‚°, ì˜¤íƒ€ ê²€ìƒ‰, ë²ˆì—­ ë“±ì˜ íŒ¨í„´ì„ few-shot learningìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŒ

![efficient-use-of-in-context-information](https://user-images.githubusercontent.com/42036664/85543587-2b1cbb00-b655-11ea-8ea1-b0e81073e755.PNG)


* ìœ„ì˜ ê·¸ë˜í”„ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´, in-context learningì˜ ê²½ìš° ê±°ëŒ€í•œ ëª¨ë¸(ë§ì€ íŒŒë¼ë¯¸í„°)ì„ ì‚¬ìš©í•  ìˆ˜ ë¡ ê·¸ ì„±ëŠ¥ì´ ì••ë„ì ìœ¼ë¡œ í–¥ìƒë¨.

ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œ ì†Œê°œí•˜ëŠ” GPT-3ëŠ” í•œë§ˆë””ë¡œ **Transformerì˜ decoder ë¶€ë¶„ì„ Autoregressive ë°©ë²•ìœ¼ë¡œ few-shot í•™ìŠµí•œ fine-tuning ê³¼ì •ì—†ëŠ” ë‹¤ìš©ë„ ìì—°ì–´ ì²˜ë¦¬ ëª¨ë¸** ì´ë‹¤.

> ì–¸ì–´ ëª¨ë¸ì€ fluidityê³¼ generalityë¥¼ ê°€ì ¸ì•¼ í•œë‹¤.

ë‹¤ì‹œ ì •ë¦¬í•˜ë©´ í•´ë‹¹ ë…¼ë¬¸ì´ ë‹¤ë£¨ëŠ” í•µì‹¬ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
1. íŒŒë¼ë¯¸í„° 1,750ì–µê°œì˜ Autoregressive(ì „ì— ë‚˜ì˜¨ í† í°ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ ì¢…ë¥˜) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ in-context learning ëŠ¥ë ¥ì„ í‰ê°€í•  ë•Œ, (24ê°œì˜ NLP datasetë“¤ì„ ì´ìš©í•˜ëŠ” taskì™€ ê¸°ì¡´ì˜ datasetì— ë“¤ì–´ìˆì§€ ì•Šì€ ì •ë³´ì— ëŒ€í•œ ìƒˆë¡œìš´ taskì— ëŒ€í•´ í‰ê°€) 3ê°€ì§€ì˜ í•™ìŠµ ë°©ë²•ì„ ì‚¬ìš©  
* `"few-shot learning"`: ëª‡ ê°œì˜ (10ê°œì—ì„œ 100ê°œ) demonstrations(ì„¤ëª… ì˜ˆì œ)ë§Œ ë³´ì—¬ì¤Œ
* `"one-shot learning"`: í•œ ê°œì˜ demonstrationë§Œ ë³´ì—¬ì¤Œ
* `"zero-shot learning"`: ì–´ëŠ demonstrationë„ ë³´ì—¬ì£¼ì§€ ì•Šê³ , ìì—°ì–´ì— ëŒ€í•œ instructionë§Œ ë³´ì—¬ì¤Œ (ì•„ì§ ì •í™•íˆ ì´í•´í•˜ì§€ ëª»í•¨.)

* GPT-3ë¥¼ fine-tuning í•  ìˆ˜ ìˆì§€ë§Œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ë£¨ì§€ ì•Šê³  future workìœ¼ë¡œ ë‚¨ê²¨ë‘”ë‹¤.

2. zero-shotê³¼ one-shotì—ì„œ promisingí•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì—ˆê³ , few-shotê°€ ëª‡ëª‡ì˜ taskì—ì„œëŠ” SOTAë¥¼ ë‹¬ì„±.
* ex) CoQA: 85.0 F1, TriviaQA: 71.2% ì •í™•ë„ ë‹¬ì„±

3. on-the-fly reasoning (ë°”ë¡œë°”ë¡œ(ì—¬ëŸ¬ ë¬¸ë§¥ì„ ë³´ì§€ ì•Šê³ ? ì†ë„?) ì¶”ë¡ í•´ì•¼í•˜ëŠ”) taskì—ì„œë„ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì„.
* ex) unscrambling words / performing arithmetic / using novel words in a sentence after seeing them defined only once.

4. ì‚¬ëŒì´ ë¶„ë³„í•  ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ ê¸°ì‚¬ ì‘ì„±.

5. ì´ëŸ¬í•œ GPT-3ì˜ ê±°ëŒ€í•œ í¬ê¸°ì—ë„ few-shot learningì´ ì œëŒ€ë¡œëœ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì§€ ëª»í•œ NLP taskê°€ ìˆìŒ.
* ì¶”ë¡  ë¬¸ì œ ANLI ë°ì´í„°ì…‹ê³¼ ë…í•´ ë¬¸ì œ RACE, QuAC ë°ì´í„°ì…‹

6. GPT-3ì˜ í•œê³„ì .

7. Commom Crawl ì‹œì— ë°ì´í„° ì˜¤ì—¼ ë¬¸ì œ ì •ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ë°©ë²• ì œì•ˆ.

8. ë¹„êµì  ì ì€ ëª¨ë¸(1.25ì–µì—ì„œ 130ì–µê°œì˜ íŒŒë¼ë¯¸í„°)ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜.

9. ì´ëŸ¬í•œ ë„“ì€ í™œìš©ì„±ìœ¼ë¡œ ì¸í•œ bias, fairness, broader societal impactë¥¼ ë‹¤ë£¸.

# 2. Approach

ë³¸ ë…¼ë¬¸ì˜ ì ‘ê·¼ ë°©ì‹ì€ ëª¨ë¸, ë°ì´í„°, í•™ìŠµ ë“± ì—¬ëŸ¬ ë©´ì—ì„œ GPT-2ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ, ëª¨ë¸ì˜ í¬ê¸°ë¥¼ í™•ì¥í•˜ê³  ë°ì´í„°ì…‹ì˜ í¬ê¸°ì™€ ë‹¤ì–‘ì„±, í•™ìŠµ ê³¼ì •ì„ ì¦ê°€ì‹œì¼°ë‹¤. ë³¸ ë‚´ìš©ì„ ì‹œì‘í•˜ê¸° ì „ì— í•´ë‹¹ ìš©ì–´ë“¤ì— ëŒ€í•œ ì •ì˜ì™€ ì°¨ì´ì ë“¤ì„ ë‹¤ë¤„ë³¸ë‹¤.

![FT-FS-1S-0S](https://user-images.githubusercontent.com/42036664/85521065-b179d280-b63e-11ea-8722-56e7d53cbce9.PNG)


* `Fine-Tuning (FT)`
ë³´í†µ ëª‡ ì²œ ë˜ëŠ” ëª‡ ë°±ê°œì˜ ë ˆì´ë¸” ë˜ì–´ ìˆëŠ” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œë‹¤. ê°€ì¥ í° ì¥ì ì€ ì—¬ëŸ¬ benchmarkì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë‚¸ë‹¤ëŠ” ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜ ê°ê°ì˜ taskì— ëŒ€í•´ ìƒˆë¡œìš´ í° ë°ì´í„°ì…‹ì´ í•„ìš”í•  ë¿ ë§Œ ì•„ë‹ˆë¼ ì¼ë°˜í™”ê°€ ë¶€ì¡±í•˜ë‹¤ëŠ” ê²ƒì´ ì•½ì ìœ¼ë¡œ ë½‘íŒë‹¤. ë˜í•œ, í•™ìŠµ ë°ì´í„°ì…‹ì˜ ì˜ëª»ëœ featureë¥¼ ì´ìš©í• ì§€ë„ ëª¨ë¥¸ë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” taskì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ”(task-agnostic) ì„±ëŠ¥ì„ ë³´ì´ê¸° ìœ„í•´ FTëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë‚˜, ì°¨í›„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° ì‹¤ì œë¡œëŠ” ìœ ë§í•œ ë°©ë²•ì´ë‹¤.   

* `Few-Shot (FS)`
ëª¨ë¸ì— ëª‡ ê°œì˜ demonstrationsë§Œ ë³´ì—¬ì£¼ê³ , ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  í•˜ëŠ”ë°, ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸ í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì´ë¥¼ learningì´ë¼ ë¶€ë¥¼ ìˆ˜ ìˆëŠ” ì§€ì™€ ì‹¤ì œë¡œ ë¬´ìŠ¨ ì˜ë¯¸ê°€ ìˆëŠ”ì§€ ì•„ì§ì€ ì´í•´ë˜ì§€ ì•ŠëŠ”ë‹¤. ì›ë¬¸ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

> the model is given a few demonstrations of the task at inference time as conditioning, but no weight updates are allowed.

* ì˜ì–´ì—ì„œ ë¶ˆì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì˜ˆë¥¼ ë“¤ë©´, $K$ê°œì˜ ì˜ì–´ì™€ ê·¸ì— ëŒ€ì‘í•˜ëŠ” ë¶ˆì–´ ì˜ˆì‹œë¥¼ ëª¨ë¸ì—ê²Œ ë³´ì—¬ì£¼ê³  ë§ˆì§€ë§‰ í•˜ë‚˜ì˜ ì˜ˆì‹œì—ì„œ ì˜ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ë¶ˆì–´ë¥¼ ì˜ˆì¸¡í•´ë³´ë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤. ì´ ë¶€ë¶„ë„ ìœ„ì—ì„œì™€ ê°™ì€ ë§¥ë½ìœ¼ë¡œ ì™„ë²½íˆ ì´í•´í•˜ì§€ ëª»í–ˆìœ¼ë©° ì›ë¬¸ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

> for a typical dataset an example has a context and a desired completion (for example an English sentence and the French translation), and few-shot works by giving K examples of context and completion, and then one final example of context, with the model expected to provide the completion.

* $K$ëŠ” ë³´í†µ 10ì—ì„œ 100ì´ë©°, ëª¨ë¸ì˜ context windowì— ë”°ë¼ ë‹¤ë¥´ë‹¤. FSì˜ ì¥ì ì€ ë‹¹ì—°íˆ ë§ì€ ë°ì´í„°ì–‘ì„ í•„ìš”ë¡œ í•˜ì§€ ì•Šìœ¼ë©°, ë§ì§€ë§Œ í˜‘ì†Œí•œ fine-tuningìš© ë°ì´í„°ì…‹ì„ í•™ìŠµí•˜ëŠ” ê°€ëŠ¥ì„±ì„ ì¤„ì¸ë‹¤.

* `One-Shot (1S)`
1Sì€ í•˜ë‚˜ì˜ demonstrationë§Œ ë³´ì—¬ì£¼ëŠ” ê²ƒì„ ì œì™¸í•˜ê³ ëŠ” FSì™€ ë™ì¼í•˜ë‹¤.

* `Zero-Shot (0S)`
0SëŠ” ì–´ëŠ demonstrationë„ ë³´ì—¬ì£¼ì§€ ì•ŠëŠ” ë‹¤ëŠ” ê²ƒì„ ì œì™¸í•˜ê³ ëŠ” 1Sì™€ ë™ì¼í•˜ë‹¤. ê°€ì¥ í¸ì˜ì ì´ê³ , ê°•ê±´í•˜ë©°, ì˜ëª»ëœ ì •ë³´ë¥¼ ìŠµë“í•  í™•ë¥ ì„ ì¤„ì—¬ì£¼ëŠ” ë°©ë²•ì´ì§€ë§Œ, ìœ„ì˜ ì„¸ ê°€ì§€ ì¤‘ ê°€ì¥ ì–´ë ¤ìš´ ë°©ë²•ì´ê¸°ë„ í•˜ë‹¤. (ì‹¬ì§€ì–´ ì‚¬ëŒì—ê²Œë„ ì–´ë ¤ìš´ taskì¼ ìˆ˜ ìˆë‹¤.)


## 2.1 Model and Architectures
![model-architecture](https://user-images.githubusercontent.com/42036664/85525439-0e2bbc00-b644-11ea-9aef-a069990cf385.PNG)

ì‚¬ìš©ëœ ëª¨ë¸ì€ GPT-2ë‘ ë™ì¼í•˜ì§€ë§Œ (modified initialization, pre-normalization, reversible tokenization), Transformer ë¶€ë¶„ì—ì„œ dense and locally banded sparse attention patternë¥¼ ì‚¬ìš©í–ˆë‹¤. (dì•„í‚¤í…ì³)

## 2.2 Training Dataset
[Common Crawl dataset](https://commoncrawl.org/the-data/)ì˜ ì›¹í¬ë¡¤ë§ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì˜€ê³ , ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë³„ë¡œ ì¢‹ì§€ ì•Šì€ ê²°ê³¼ë¥¼ ë‚´ì–´ ë‹¤ìŒ 3ê°€ì§€ ì „ì²˜ë¦¬ ê³¼ì •ì„ ì§„í–‰í•˜ì˜€ë‹¤.
1. CommonCrawl ë°ì´í„°ì…‹ì„ high-quality reference corporaë¡œ í•„í„°ë§í•˜ê³ ,
2. ë¬¸ì„œ ë ˆë²¨ì—ì„œ fuzzy deduplicationë¥¼ ìˆ˜í–‰í•˜ê³ ,
3. high-quality reference corpora(WebText ë“±)ë¥¼ í•™ìŠµì‹œì— ì¶”ê°€í•˜ì˜€ë‹¤.

![dataset](https://user-images.githubusercontent.com/42036664/85538580-fd814300-b64f-11ea-8a96-be9157ab6bb1.PNG)


## 2.3 Training Process

## 2.4 Evaluation

# 3. Results

GPTì˜ ê³ ì§ˆì ì¸ ë¬¸ì œëŠ” ì–‘ë°©í–¥ ì •ë³´ë¥¼ íšë“í•  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì¸ë°, ì´ ì ì´ ì„±ëŠ¥ í‰ê°€ì—ì„œ ê³ ìŠ¤ë€íˆ ë‚˜íƒ€ë‚¬ë‹¤.

# 4. Measuring and Preventing Memorization Of Benchmarks

# 5. Limitations

# 6. Broader Impacts
